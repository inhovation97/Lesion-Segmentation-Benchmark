{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8rAU9PR_6LB"
   },
   "source": [
    "### 초기 경로 설정 (클래스 이용을 위함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /project/segmentation/smcho1201/segmentation_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files and system\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "# working with images\n",
    "import cv2\n",
    "import imageio\n",
    "import scipy.ndimage\n",
    "# import skimage.transform\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torchsummary\n",
    "from tqdm import notebook\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# losses\n",
    "from utils.metrics import iou_pytorch_eval, IoULoss, IoUBCELoss, DiceBCELoss , dice_pytorch_eval\n",
    "from utils.metrics import iou_pytorch_test, dice_pytorch_test, precision_pytorch_test, recall_pytorch_test, fbeta_pytorch_test, accuracy_pytorch_test\n",
    "\n",
    "# dataset\n",
    "from utils.dataset import myDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NWsOfmf_6LH"
   },
   "source": [
    "## 랜덤성을 배제한 환경 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1663841626889,
     "user": {
      "displayName": "김동현",
      "userId": "12784596420296644443"
     },
     "user_tz": -540
    },
    "id": "AVUjKR9g_6LI"
   },
   "outputs": [],
   "source": [
    "random_seed= 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1663841626889,
     "user": {
      "displayName": "김동현",
      "userId": "12784596420296644443"
     },
     "user_tz": -540
    },
    "id": "__iQco2m_6LI"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # select device for training, i.e. gpu or cpu\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hE6MqJ9_6LL"
   },
   "source": [
    "# 1. Image augentation\n",
    "> 실험할 때는 아예 augmentation도 고정시켜서 저장한 이미지를 사용해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1663841626890,
     "user": {
      "displayName": "김동현",
      "userId": "12784596420296644443"
     },
     "user_tz": -540
    },
    "id": "QsLMJcor_6LL"
   },
   "outputs": [],
   "source": [
    "_size = 224, 224\n",
    "resize = transforms.Resize(_size, interpolation=0)\n",
    "\n",
    "# set your transforms \n",
    "train_transforms = transforms.Compose([\n",
    "                           transforms.Resize(_size, interpolation=0),\n",
    "                           transforms.RandomRotation(180),\n",
    "                           transforms.RandomHorizontalFlip(0.5),\n",
    "                           transforms.RandomCrop(_size, padding = 10), # needed after rotation (with original size)\n",
    "                       ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.Resize(_size, interpolation=0),\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-idQzI2_6LM"
   },
   "source": [
    "# 2. 데이터셋 클래스 생성\n",
    "> 해당 클래스는 이용하려는 이미지와 라벨의 모든 경로(/data/segmentation/...)의 리스트를 인자로 받는다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = glob.glob('/data/segmentation/breast-cancer/trainset_benign/images/*')\n",
    "train_labels = glob.glob('/data/segmentation/breast-cancer/trainset_benign/labels/*')\n",
    "train_images = [img for img in train_images if img.find('jpg')!= -1] # super pixels 이미지 제외\n",
    "\n",
    "valid_images = glob.glob('/data/segmentation/breast-cancer/validationset_benign/images/*')\n",
    "valid_labels = glob.glob('/data/segmentation/breast-cancer/validationset_benign/labels/*')\n",
    "valid_images = [img for img in valid_images if img.find('jpg')!= -1] # super pixels 이미지 제외\n",
    "\n",
    "train_images = sorted(train_images)\n",
    "train_labels = sorted(train_labels)\n",
    "\n",
    "valid_images = sorted(valid_images)\n",
    "valid_labels = sorted(valid_labels)\n",
    "\n",
    "# 데이터셋 클래스 적용\n",
    "custom_dataset_train = myDataSet(train_images, train_labels, transforms=test_transforms)\n",
    "print(\"My custom training-dataset has {} elements\".format(len(custom_dataset_train)))\n",
    "\n",
    "custom_dataset_val = myDataSet(valid_images, valid_labels, transforms=test_transforms)\n",
    "print(\"My custom valing-dataset has {} elements\".format(len(custom_dataset_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset class check\n",
    "> RGB 채널 평균 값이라 색 바뀜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1663841626892,
     "user": {
      "displayName": "김동현",
      "userId": "12784596420296644443"
     },
     "user_tz": -540
    },
    "id": "GIUSSxLR_6LO"
   },
   "outputs": [],
   "source": [
    "# Show example images.\n",
    "image_number = 23\n",
    "img, mask = custom_dataset_train.__getitem__(image_number)\n",
    "\n",
    "# image\n",
    "plt.figure()\n",
    "plt.imshow(img.mean(0)) # 3 channels, take mean\n",
    "\n",
    "# mask\n",
    "plt.figure()\n",
    "plt.imshow(mask[0, :, :]) # 1 channel, take it\n",
    "\n",
    "plt.show()\n",
    "print('3픽셀의 평균값이라 색깔이 변경됨.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFBEH3fL_6LS"
   },
   "source": [
    "# 3. 모델 클래스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1663841626892,
     "user": {
      "displayName": "김동현",
      "userId": "12784596420296644443"
     },
     "user_tz": -540
    },
    "id": "xi7xpY2T_6LS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mmseg.models.segmentors.colonformer import ColonFormer\n",
    "from mmseg.models.decode_heads.uper_head import UPerHead\n",
    "\n",
    "backbone=dict(type='mit_b3',style='pythorch')\n",
    "\n",
    "decode_head=dict(type='UPerHead', in_channels=[64], in_index=[0], channels=128, dropout_ratio=0.1,\n",
    "                    num_classes=1, norm_cfg=dict(type='BN', requires_grad=True), align_corners=False,decoder_params=dict(embed_dim=768),\n",
    "                    loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0))\n",
    "\n",
    "\n",
    "model = ColonFormer(backbone,decode_head = decode_head,\n",
    "                neck=None,\n",
    "                auxiliary_head=None,\n",
    "                train_cfg=dict(),\n",
    "                test_cfg=dict(mode='whole'),\n",
    "                pretrained='mmseg/pretrained/mit_b3.pth')\n",
    "\n",
    "params = model.parameters()\n",
    "model = model.to(DEVICE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 하이퍼 파라미터 세팅 & 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1663841626893,
     "user": {
      "displayName": "김동현",
      "userId": "12784596420296644443"
     },
     "user_tz": -540
    },
    "id": "OoO7N525_6LS"
   },
   "outputs": [],
   "source": [
    "# Define variables for the training\n",
    "epochs = 100\n",
    "patience = 20\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(custom_dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "dataloader_val = torch.utils.data.DataLoader(custom_dataset_val, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1663841626893,
     "user": {
      "displayName": "김동현",
      "userId": "12784596420296644443"
     },
     "user_tz": -540
    },
    "id": "CNybC4HK_6LS"
   },
   "outputs": [],
   "source": [
    "# Define optimiser and criterion for the training. You can try different ones to see which works best for your data and task\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4, weight_decay = 1e-8)\n",
    "\n",
    "criterion = DiceBCELoss()\n",
    "model_name = 'ColonFormer'\n",
    "data_name = 'benign'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7KHm3Y9_6LT"
   },
   "source": [
    "# 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1663841626893,
     "user": {
      "displayName": "김동현",
      "userId": "12784596420296644443"
     },
     "user_tz": -540
    },
    "id": "7TdAxM9O_6LT"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from ploting import plot_model_prediction\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_ious, val_ious = [], []\n",
    "train_dices, val_dices = [], []\n",
    "best_iou, best_dice, best_loss = 0, 0, np.inf\n",
    "best_epoch_dice = -1\n",
    "state = {}\n",
    "lst_epoch_metric = []\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1, epochs+1):\n",
    "    running_loss, running_iou, running_dice = 0, 0, 0\n",
    "\n",
    "    # Train\n",
    "    model.train()\n",
    "    for i, (imgs, masks) in enumerate(dataloader_train):\n",
    "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "        \n",
    "        prediction = model(imgs)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(prediction, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_iou += iou_pytorch_eval(prediction, masks)\n",
    "        running_dice += dice_pytorch_eval(prediction, masks)\n",
    "        print(\"\\r Epoch: {} of {}, Iter.: {} of {}, Loss: {:.6f}, IoU:  {:.6f},  Dice:  {:.6f}\".format(epoch, epochs, i, len(dataloader_train), running_loss/(i+1), running_iou/(i+1), running_dice/(i+1)), end=\"\")\n",
    "        \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    val_loss, val_iou, val_dice = 0, 0, 0\n",
    "    for i, (imgs, masks) in enumerate(dataloader_val):\n",
    "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "        \n",
    "        prediction = model(imgs)\n",
    "        loss = criterion(prediction, masks)\n",
    "        val_loss += loss.item()\n",
    "        print(\"\\r Epoch: {} of {}, Iter.: {} of {}, Loss: {:.6f}, Val. Loss: {:.6f}\".format(epoch, epochs, len(dataloader_train), len(dataloader_train), running_loss/len(dataloader_train), val_loss/(i+1)), end=\"\")\n",
    "        \n",
    "        val_iou += iou_pytorch_eval(prediction, masks)\n",
    "        print(\"\\r Epoch: {} of {}, Iter.: {} of {}, IoU: {:.6f}, Val. IoU: {:.6f}\".format(epoch, epochs, len(dataloader_train), len(dataloader_train), running_iou/len(dataloader_train), val_iou/(i+1)), end=\"\")\n",
    "\n",
    "        val_dice += dice_pytorch_eval(prediction, masks)\n",
    "        print(\"\\r Epoch: {} of {}, Iter.: {} of {}, Dice: {:.6f}, Val. Dice: {:.6f}\".format(epoch, epochs, len(dataloader_train), len(dataloader_train), running_dice/len(dataloader_train), val_dice/(i+1)), end=\"\")\n",
    "    \n",
    "    \n",
    "    # compute overall epoch losses\n",
    "    epoch_train_loss = running_loss/len(dataloader_train)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    epoch_val_loss = val_loss/len(dataloader_val)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    # compute overall epoch iou-s\n",
    "    epoch_train_iou = (running_iou/len(dataloader_train)).item()\n",
    "    train_ious.append(epoch_train_iou)\n",
    "    epoch_val_iou = (val_iou/len(dataloader_val)).item()\n",
    "    val_ious.append(epoch_val_iou)\n",
    "    \n",
    "    # compute overall epoch dice\n",
    "    epoch_train_dice = (running_dice/len(dataloader_train)).item()\n",
    "    train_dices.append(epoch_train_dice)\n",
    "    epoch_val_dice = (val_dice/len(dataloader_val)).item()\n",
    "    val_dices.append(epoch_val_dice)\n",
    "\n",
    "    print(\"\\r Epoch: {} of {}, Iter.: {} of {}, Train Loss: {:.6f}, IoU: {:.6f}, Dice: {:.6f}\".format(epoch, epochs, len(dataloader_train), len(dataloader_train), epoch_train_loss, epoch_train_iou, epoch_train_dice))\n",
    "    print(\"\\r Epoch: {} of {}, Iter.: {} of {}, Valid Loss: {:.6f}, IoU: {:.6f}, Dice: {:.6f}\".format(epoch, epochs, len(dataloader_train), len(dataloader_train), epoch_val_loss, epoch_val_iou, epoch_val_dice))\n",
    "    \n",
    "    if epoch == 1:\n",
    "        print('\\n시각화되는 이미지는 1.실제 테스트 이미지 2.실제 라벨 이미지 3.예측 라벨 4.예측한 이미지 결과의 순서입니다.')\n",
    "    plot_model_prediction(model, DEVICE, valid_images, valid_labels)\n",
    "        \n",
    "    # plot\n",
    "    metrics = {'loss':[train_losses, epoch_train_loss, val_losses, epoch_val_loss],\n",
    "               'Iou':[train_ious, epoch_train_iou, val_ious,  epoch_val_iou],\n",
    "               'Dice':[train_dices, epoch_train_dice, val_dices,  epoch_val_dice]}\n",
    "    \n",
    "    lst_epoch_metric.append([round(epoch_train_loss,4), round(epoch_train_iou,4), round(epoch_train_dice,4), \n",
    "                             round(epoch_val_loss,4), round(epoch_val_iou,4), round(epoch_val_dice,4)]) \n",
    "\n",
    "    # save if best results or break is has not improved for {patience} number of epochs\n",
    "    best_iou = max(best_iou, epoch_val_iou)\n",
    "    best_dice = max(best_dice, epoch_val_dice)\n",
    "    best_loss = min(best_loss, epoch_val_loss)\n",
    "    best_epoch_dice = epoch if best_dice == epoch_val_dice else best_epoch_dice\n",
    "\n",
    "    # record losses\n",
    "    state['train_losses'] = train_losses\n",
    "    state['val_losses'] = val_losses\n",
    "    \n",
    "    if best_epoch_dice == epoch:\n",
    "        # print('Saving..')\n",
    "        state['net'] = model.state_dict()\n",
    "        state['dice'] = best_dice\n",
    "        state['epoch'] = epoch\n",
    "            \n",
    "        if not os.path.isdir('checkpoints'):\n",
    "            os.mkdir('checkpoints')\n",
    "        torch.save(state, f'./checkpoints/ckpt_{model_name}_{data_name}.pth')\n",
    "    \n",
    "    \n",
    "    elif best_epoch_dice + patience < epoch:\n",
    "        print(f\"\\nEarly stopping. Target criteria has not improved for {patience} epochs.\\n\")\n",
    "        break\n",
    "\n",
    "file_name = f'{model_name}_{data_name}'\n",
    "# load once more and write all the losses down (othw can miss the last 10)\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "state = torch.load(f'./checkpoints/ckpt_{model_name}_{data_name}.pth')\n",
    "state['train_losses'] = train_losses\n",
    "state['val_losses'] = val_losses\n",
    "torch.save(state, f'./checkpoints/ckpt_{model_name}_{data_name}.pth')\n",
    "\n",
    "df_epoch_metric = pd.DataFrame(lst_epoch_metric, columns = ['epoch_train_loss', 'epoch_train_iou', 'epoch_train_dice', 'epoch_val_loss', 'epoch_val_iou', 'epoch_val_dice'])\n",
    "df_epoch_metric.to_csv(f'/project/segmentation/ehdgus575/training_{model_name}/csv_{file_name}.csv', index_label = ['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCcUpTDi_6LU"
   },
   "outputs": [],
   "source": [
    "print(f'Validationset 기준 \\nBest_epoch:{best_epoch_dice}, Best_IOU:{best_iou:.4f}, Best_DiceScore:{best_dice:.4f}')\n",
    "#print(f'End_time: {end_time}')\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(18, 9))           \n",
    "for i, (metric, value) in enumerate(metrics.items()):\n",
    "    axs[i].plot(np.arange(len(value[0])), value[0], label=f'Train, {metric}: {value[1]:.4f}', linewidth=2)\n",
    "    axs[i].plot(np.arange(len(value[2])), value[2], label=f'Valid, {metric}: {value[3]:.4f}', linewidth=2)\n",
    "    axs[i].set_xlabel('Epoch')\n",
    "    axs[i].set_ylabel('Loss')\n",
    "    axs[i].set_title(f'{metric} ,Epoch {epoch} ')\n",
    "    axs[i].legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "torch_sm",
   "language": "python",
   "name": "torch_sm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
